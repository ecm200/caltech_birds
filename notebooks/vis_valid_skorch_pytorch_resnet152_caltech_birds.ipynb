{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local modules\n",
    "from cub_tools.train import train_model\n",
    "from cub_tools.visualize import imshow, visualize_model\n",
    "from cub_tools.utils import unpickle, save_pickle\n",
    "from cub_tools.transforms import makeDefaultTransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script runtime options\n",
    "model_names = ['resnet152', 'resnext101_32x8d', 'inception_v3', 'googlenet']\n",
    "data_parallel = {'resnet152' : False,\n",
    "                 'inceptionv4' : True,\n",
    "                 'resnext101_64x4d' : True, \n",
    "                 'pnasnet5large' : True, \n",
    "                 'googlenet' : False,\n",
    "                 'inception_v3' : False, \n",
    "                 'resnext101_32x8d' : False}\n",
    "data_root_dir = '../data'\n",
    "model_root_dir = '../models'\n",
    "stages = ['train', 'test']\n",
    "\n",
    "\n",
    "# Paths setup\n",
    "data_dir = os.path.join(data_root_dir,'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data transforms\n",
    "data_transforms = makeDefaultTransforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data loaders with augmentation transforms\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in stages}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in stages}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in stages}\n",
    "class_names = image_datasets[stages[0]].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to run the computations\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device::', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model resnet152\n",
      "[INFO] Loading model resnext101_32x8d\n",
      "[INFO] Loading model inception_v3\n",
      "[INFO] Loading model googlenet\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    \n",
    "    print('[INFO] Loading model {}'.format(model_name))\n",
    "    \n",
    "    # Paths\n",
    "    output_dir = os.path.join(model_root_dir,'classification/{}'.format(model_name))\n",
    "    model_file = os.path.join(output_dir, 'caltech_birds_{}_full.pth'.format(model_name))\n",
    "    \n",
    "    # Load the best model from file\n",
    "    models[model_name] = torch.load(model_file)\n",
    "    if data_parallel[model_name]:\n",
    "        models[model_name] = torch.nn.DataParallel(model[model_name])\n",
    "    models[model_name] = models[model_name].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = {}\n",
    "for model_name in model_names:\n",
    "    net[model_name] = NeuralNetClassifier(models[model_name])\n",
    "    net[model_name].initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "Different approaches for ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking ensemble bespoke implementation\n",
    "\n",
    "Following the tutorial here: https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# TODO: refactor so that it accepts a dataloader instance and iterates over the whole dataset.\n",
    "#       Add as an outer loop and then run each model on an inner loop, so that they use the same images.\n",
    "#       Remember to also keep the labels for later use and return them\n",
    "def stacked_dataset(models, inputs):\n",
    "    stackX = None\n",
    "    for model_name, model in models.items():\n",
    "        # make prediction\n",
    "        yhat = model.predict_proba(inputs)\n",
    "        for i in np.arange(0, yhat.shape[0], 1):\n",
    "            yhat[i, ::] = softmax(yhat[i,::])\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = dstack((stackX, yhat))\n",
    "        print('{}...'.format(model_name), end='')\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX\n",
    "\n",
    "def stacked_dataset_from_dataloader(models, dataloader, device):\n",
    "    stackX = None\n",
    "    stacky = None\n",
    "    print('[INFO] Starting StackX', end='')\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            while i < (len(dataloader)-1):\n",
    "                temp_stack = None\n",
    "                for model_name, model in models.items():\n",
    "                    # make prediction\n",
    "                    if isinstance(model, skorch.classifier.NeuralNetClassifier):\n",
    "                        yhat = model.predict_proba(inputs)\n",
    "                    else:\n",
    "                        model.eval()\n",
    "                        inputs = inputs.to(device)\n",
    "                        yhat = model(inputs)\n",
    "                        yhat = yhat.cpu().numpy()\n",
    "\n",
    "                    # Convert score to probability\n",
    "                    for i in np.arange(0, yhat.shape[0], 1):\n",
    "                        yhat[i, ::] = softmax(yhat[i,::])\n",
    "\n",
    "                    # stack predictions into [rows, members, probabilities]\n",
    "                    if temp_stack is None:\n",
    "                        temp_stack = yhat\n",
    "                    else:\n",
    "                        temp_stack = dstack((temp_stack, yhat))\n",
    "\n",
    "                # flatten predictions to [rows, members x probabilities]\n",
    "                temp_stack = temp_stack.reshape((temp_stack.shape[0], temp_stack.shape[1]*temp_stack.shape[2]))\n",
    "                # stack the batch of model probabilities onto the bottom of the results table\n",
    "                if stackX is None:\n",
    "                    stackX = temp_stack\n",
    "                else:\n",
    "                    stackX = np.vstack((stackX, temp_stack))\n",
    "\n",
    "                # stack the output truth labels to bottom of truth labels table\n",
    "                if stacky is None:\n",
    "                    stacky = labels.cpu().numpy()\n",
    "                else:\n",
    "                    stacky = np.vstack((stacky, labels.cpu().numpy()))\n",
    "                    \n",
    "                if i % 25 == 0:\n",
    "                    print('{}..'.format(i), end='')\n",
    "    \n",
    "    print('Complete')\n",
    "    return stackX, stacky\n",
    "\n",
    "# fit a model based on the outputs from the ensemble members\n",
    "def fit_stacked_model(models, dataloader=None, stackX=None, labels=None, meta_learner=LogisticRegression):\n",
    "    # create dataset using ensemble\n",
    "    if (stackX is None) or (labels is None):\n",
    "        print('[INFO] Creating the meta learner inputs (probabilities from individual models) as none provided.')\n",
    "        stackedX, labels = stacked_dataset_from_dataloader(models, dataloader)\n",
    "    else:\n",
    "        print('[INFO] Stacked input table and labels found, using these to train meta learner.')\n",
    "    \n",
    "    # fit standalone model\n",
    "    print('[INFO] Training the meta learner...', end='')\n",
    "    meta_model = meta_learner()\n",
    "    meta_model.fit(stackedX, labels)\n",
    "    print('Complete')\n",
    "    return meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting StackX"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bcdaa0e470a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate the stacked dataset from the ensemble models for the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstackY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_dataset_from_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-19a7f1114504>\u001b[0m in \u001b[0;36mstacked_dataset_from_dataloader\u001b[0;34m(models, dataloader, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;31m# Convert score to probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate the stacked dataset from the ensemble models for the training data\n",
    "stackY, stackx = stacked_dataset_from_dataloader(models, dataloaders['train'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = fit_stacked_model(models=models, stackX=stackX, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['train'].batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "net = {}\n",
    "output = {}\n",
    "with torch.no_grad():\n",
    "    for model_name in model_names:\n",
    "\n",
    "        net[model_name] = NeuralNetClassifier(model[model_name])\n",
    "        net[model_name].initialize()\n",
    "        \n",
    "        output[model_name] = net[model_name].predict(inputs)\n",
    "\n",
    "for i_res, truth in enumerate(classes.numpy()):\n",
    "    res_str = 'Truth: {:5}  Pred:'.format(truth)\n",
    "    for model_name in model_names:\n",
    "        res_str = res_str + ' {:5}'.format(output[model_name][i_res])\n",
    "    print(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combo.models.classifier_comb import SimpleClassifierAggregator\n",
    "#from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_model = SimpleClassifierAggregator(base_estimators=list(net.values()),\n",
    "                                         method='majority_vote',\n",
    "                                         pre_fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "py37_pytorch_003",
   "language": "python",
   "name": "conda-env-py37_pytorch_003-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
